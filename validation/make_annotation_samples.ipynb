{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data/episodes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is this discussing race?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sentence sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import random\n",
    "# import pandas as pd\n",
    "\n",
    "# reservoir_0 = []\n",
    "# reservoir_1 = []\n",
    "# target_size = 100\n",
    "# total_seen_0 = 0\n",
    "# total_seen_1 = 0\n",
    "\n",
    "# random.seed(42)\n",
    "\n",
    "# csv_files = glob.glob(os.path.join(directory, \"*.csv\"))\n",
    "\n",
    "# for path in csv_files:\n",
    "#     try:\n",
    "#         df = pd.read_csv(path)\n",
    "#         df = df[df['collectiveActionLevel'] != 'error']\n",
    "\n",
    "#         for _, row in df[df['race'] == 0].iterrows():\n",
    "#             total_seen_0 += 1\n",
    "#             if len(reservoir_0) < target_size:\n",
    "#                 reservoir_0.append(row)\n",
    "#             else:\n",
    "#                 idx = random.randint(0, total_seen_0 - 1)\n",
    "#                 if idx < target_size:\n",
    "#                     reservoir_0[idx] = row\n",
    "\n",
    "#         for _, row in df[df['race'] == 1].iterrows():\n",
    "#             total_seen_1 += 1\n",
    "#             if len(reservoir_1) < target_size:\n",
    "#                 reservoir_1.append(row)\n",
    "#             else:\n",
    "#                 idx = random.randint(0, total_seen_1 - 1)\n",
    "#                 if idx < target_size:\n",
    "#                     reservoir_1[idx] = row\n",
    "\n",
    "#         # Stop early if both are full\n",
    "#         if len(reservoir_0) == target_size and len(reservoir_1) == target_size:\n",
    "#             break\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Skipping file {path}: {e}\")\n",
    "\n",
    "# # Combine and shuffle\n",
    "# race_sampled_df = pd.DataFrame(reservoir_0 + reservoir_1).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence + 2 before/after sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir_0 = []\n",
    "reservoir_1 = []\n",
    "target_size = 100\n",
    "total_seen_0 = 0\n",
    "total_seen_1 = 0\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "csv_files = glob.glob(os.path.join(directory, \"*.csv\"))\n",
    "\n",
    "for path in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        df = df[df['collectiveActionLevel'] != 'error']\n",
    "        df = df.reset_index(drop=True) \n",
    "\n",
    "        for i in range(2, len(df) - 2):\n",
    "            row = df.loc[i]\n",
    "\n",
    "            if pd.isna(row['race']):\n",
    "                continue\n",
    "\n",
    "            window_df = df.loc[i - 2:i + 2]\n",
    "            concatenated_sentence = \" \".join(str(s) for s in window_df['sentence'])\n",
    "\n",
    "            new_row = {\n",
    "                'sentenceID': row['sentenceID'],  # ID of the center sentence\n",
    "                'concatenated_sentence': concatenated_sentence,\n",
    "                'collectiveAction': row['collectiveAction'],\n",
    "                'probCollectiveAction': row['probCollectiveAction'],\n",
    "                'collectiveActionLevel': row['collectiveActionLevel'],\n",
    "                'race': row['race'],\n",
    "                'source_file': os.path.basename(path)\n",
    "            }\n",
    "\n",
    "            if row['race'] == 0:\n",
    "                total_seen_0 += 1\n",
    "                if len(reservoir_0) < target_size:\n",
    "                    reservoir_0.append(new_row)\n",
    "                else:\n",
    "                    idx = random.randint(0, total_seen_0 - 1)\n",
    "                    if idx < target_size:\n",
    "                        reservoir_0[idx] = new_row\n",
    "\n",
    "            elif row['race'] == 1:\n",
    "                total_seen_1 += 1\n",
    "                if len(reservoir_1) < target_size:\n",
    "                    reservoir_1.append(new_row)\n",
    "                else:\n",
    "                    idx = random.randint(0, total_seen_1 - 1)\n",
    "                    if idx < target_size:\n",
    "                        reservoir_1[idx] = new_row\n",
    "\n",
    "        if len(reservoir_0) == target_size and len(reservoir_1) == target_size:\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {path}: {e}\")\n",
    "\n",
    "race_sampled_df = pd.DataFrame(reservoir_0 + reservoir_1).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full version\n",
    "race_sampled_df[['sentenceID', 'concatenated_sentence', 'race', 'collectiveAction', 'probCollectiveAction', 'collectiveActionLevel']].to_csv(\n",
    "    '../data/annotation/race_sample_context.csv', index=False\n",
    ")\n",
    "\n",
    "# Create and save anonymized version\n",
    "anon_df = race_sampled_df[['concatenated_sentence']].copy()\n",
    "anon_df['annotation'] = ''  # Placeholder column for annotators\n",
    "\n",
    "anon_df.to_csv('../data/annotation/race_sample_context_anon.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is this collective action?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reservoir_0 = []\n",
    "# reservoir_1 = []\n",
    "# target_size = 100  # Number of samples per class\n",
    "# total_seen_0 = 0\n",
    "# total_seen_1 = 0\n",
    "\n",
    "# csv_files = glob.glob(os.path.join(directory, \"*.csv\"))\n",
    "# random.seed(42)\n",
    "\n",
    "# print(f\"Total files found: {len(csv_files)}\")\n",
    "\n",
    "# for path in csv_files:\n",
    "#     try:\n",
    "#         df = pd.read_csv(path)\n",
    "\n",
    "#         df = df[df['race'] == 1]\n",
    "\n",
    "#         # Count class distributions\n",
    "#         count_0 = (df['collectiveAction'] == 0).sum()\n",
    "#         count_1 = (df['collectiveAction'] == 1).sum()\n",
    "#         #print(f\"{os.path.basename(path)} — class 0: {count_0}, class 1: {count_1}\")\n",
    "\n",
    "#         # Add class 0 samples\n",
    "#         for _, row in df[df['collectiveAction'] == 0].iterrows():\n",
    "#             total_seen_0 += 1\n",
    "#             if len(reservoir_0) < target_size:\n",
    "#                 reservoir_0.append(row)\n",
    "#             else:\n",
    "#                 idx = random.randint(0, total_seen_0 - 1)\n",
    "#                 if idx < target_size:\n",
    "#                     reservoir_0[idx] = row\n",
    "\n",
    "#         # Add class 1 samples\n",
    "#         for _, row in df[df['collectiveAction'] == 1].iterrows():\n",
    "#             total_seen_1 += 1\n",
    "#             if len(reservoir_1) < target_size:\n",
    "#                 reservoir_1.append(row)\n",
    "#             else:\n",
    "#                 idx = random.randint(0, total_seen_1 - 1)\n",
    "#                 if idx < target_size:\n",
    "#                     reservoir_1[idx] = row\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Skipping file {path} due to error: {e}\")\n",
    "\n",
    "# # Final class sizes\n",
    "# print(f\"\\nFinal collected — class 0: {len(reservoir_0)}, class 1: {len(reservoir_1)}\")\n",
    "\n",
    "# # Warn if under-sampled\n",
    "# if len(reservoir_0) < target_size or len(reservoir_1) < target_size:\n",
    "#     print(\"Warning: Not enough data to sample both classes to target size.\")\n",
    "\n",
    "# # Create final shuffled DataFrame\n",
    "# df_0 = pd.DataFrame(reservoir_0)\n",
    "# df_1 = pd.DataFrame(reservoir_1)\n",
    "# binary_sampled_df = pd.concat([df_0, df_1], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 139200\n",
      "\n",
      "Final collected — class 0: 100, class 1: 100\n",
      "\n",
      "Sampled class distribution:\n",
      "collectiveAction\n",
      "0    100\n",
      "1    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "reservoir_0 = []\n",
    "reservoir_1 = []\n",
    "target_size = 100\n",
    "total_seen_0 = 0\n",
    "total_seen_1 = 0\n",
    "\n",
    "random.seed(42)\n",
    "csv_files = glob.glob(os.path.join(directory, \"*.csv\"))\n",
    "print(f\"Total files found: {len(csv_files)}\")\n",
    "\n",
    "for path in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        if 'race' not in df.columns or 'collectiveAction' not in df.columns:\n",
    "            continue\n",
    "\n",
    "        df = df[(df['race'] == 1) & (df['collectiveActionLevel'] != 'error')]\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        for i in range(2, len(df) - 2):\n",
    "            row = df.loc[i]\n",
    "\n",
    "            if pd.isna(row['race']) or row['collectiveAction'] not in [0, 1]:\n",
    "                continue\n",
    "\n",
    "            window_df = df.loc[i - 2:i + 2]\n",
    "            concatenated_sentence = \" \".join(str(s) for s in window_df['sentence'])\n",
    "\n",
    "            new_row = {\n",
    "                'sentenceID': row['sentenceID'],\n",
    "                'concatenated_sentence': concatenated_sentence,\n",
    "                'collectiveAction': row['collectiveAction'],\n",
    "                'probCollectiveAction': row['probCollectiveAction'],\n",
    "                'collectiveActionLevel': row['collectiveActionLevel'],\n",
    "                'race': row['race'],\n",
    "                'source_file': os.path.basename(path)\n",
    "            }\n",
    "\n",
    "            if row['collectiveAction'] == 0:\n",
    "                total_seen_0 += 1\n",
    "                if len(reservoir_0) < target_size:\n",
    "                    reservoir_0.append(new_row)\n",
    "                else:\n",
    "                    idx = random.randint(0, total_seen_0 - 1)\n",
    "                    if idx < target_size:\n",
    "                        reservoir_0[idx] = new_row\n",
    "\n",
    "            elif row['collectiveAction'] == 1:\n",
    "                total_seen_1 += 1\n",
    "                if len(reservoir_1) < target_size:\n",
    "                    reservoir_1.append(new_row)\n",
    "                else:\n",
    "                    idx = random.randint(0, total_seen_1 - 1)\n",
    "                    if idx < target_size:\n",
    "                        reservoir_1[idx] = new_row\n",
    "\n",
    "        # Early exit if both samples are full\n",
    "        if len(reservoir_0) == target_size and len(reservoir_1) == target_size:\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {path} due to error: {e}\")\n",
    "\n",
    "print(f\"\\nFinal collected — class 0: {len(reservoir_0)}, class 1: {len(reservoir_1)}\")\n",
    "if len(reservoir_0) < target_size or len(reservoir_1) < target_size:\n",
    "    print(\"Warning: Not enough data to sample both classes to target size.\")\n",
    "\n",
    "# Combine and shuffle\n",
    "binary_sampled_df = pd.DataFrame(reservoir_0 + reservoir_1).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full version\n",
    "binary_sampled_df[['sentenceID', 'concatenated_sentence', 'collectiveAction', 'probCollectiveAction', 'collectiveActionLevel', 'race']].to_csv(\n",
    "    '../data/annotation/binary_sample_context.csv', index=False\n",
    ")\n",
    "\n",
    "# Create and save anonymized version\n",
    "anon_df = binary_sampled_df[['concatenated_sentence']].copy()\n",
    "anon_df['annotation'] = ''  # Placeholder column for annotators\n",
    "\n",
    "anon_df.to_csv('../data/annotation/binary_sample_context_anon.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full version\n",
    "binary_sampled_df[['sentenceID', 'sentence', 'collectiveAction', 'probCollectiveAction', 'collectiveActionLevel', 'race']].to_csv(\n",
    "    '../data/annotation/binary_sample.csv', index=False\n",
    ")\n",
    "\n",
    "# Create and save anonymized version\n",
    "anon_df = binary_sampled_df[['sentence']].copy()\n",
    "anon_df['annotation'] = ''  # Placeholder column for annotators\n",
    "\n",
    "anon_df.to_csv('../data/annotation/binary_sample_anon.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What level of collective action is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "category_counts = {\n",
    "    \"problem-solution\": 6_500_000,\n",
    "    \"call-to-action\": 1_300_000,\n",
    "    \"intention\": 1_700_000,\n",
    "    \"execution\": 861_000\n",
    "}\n",
    "\n",
    "total = sum(category_counts.values())\n",
    "weights = {k: v / total for k, v in category_counts.items()}\n",
    "\n",
    "target_n = 300\n",
    "normalized_sample_sizes = {k: int(round(w * target_n)) for k, w in weights.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem-solution': 188,\n",
       " 'call-to-action': 38,\n",
       " 'intention': 49,\n",
       " 'execution': 25}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_sample_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/tmp.4689191/ipykernel_3955519/2938665679.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_filtered = pd.concat(matching_rows, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenceID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>collectiveAction</th>\n",
       "      <th>probCollectiveAction</th>\n",
       "      <th>collectiveActionLevel</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1123280_564</td>\n",
       "      <td>I also wanted to take our anger, our frustrati...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9997795224189758, 0.00022051949054002762]</td>\n",
       "      <td>Call-to-Action</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1096670_201</td>\n",
       "      <td>A ban on police choke holds, for example, and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9997624754905701, 0.00023757819144520909]</td>\n",
       "      <td>Intention</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1052900_394</td>\n",
       "      <td>I mean, it's so ingrained into, you know, just...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.707208514213562, 0.292791485786438]</td>\n",
       "      <td>Problem-Solution</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104899_504</td>\n",
       "      <td>They do themselves, they do wear clothes, they...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9968287348747253, 0.0031712749041616917]</td>\n",
       "      <td>Problem-Solution</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122201_445</td>\n",
       "      <td>Justice has to be for everyone.</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9995554089546204, 0.00044457122567109764]</td>\n",
       "      <td>Intention</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentenceID                                           sentence  \\\n",
       "0  1123280_564  I also wanted to take our anger, our frustrati...   \n",
       "1  1096670_201  A ban on police choke holds, for example, and ...   \n",
       "2  1052900_394  I mean, it's so ingrained into, you know, just...   \n",
       "3  1104899_504  They do themselves, they do wear clothes, they...   \n",
       "4   122201_445                    Justice has to be for everyone.   \n",
       "\n",
       "   collectiveAction                          probCollectiveAction  \\\n",
       "0                 0  [0.9997795224189758, 0.00022051949054002762]   \n",
       "1                 0  [0.9997624754905701, 0.00023757819144520909]   \n",
       "2                 0        [0.707208514213562, 0.292791485786438]   \n",
       "3                 0   [0.9968287348747253, 0.0031712749041616917]   \n",
       "4                 0  [0.9995554089546204, 0.00044457122567109764]   \n",
       "\n",
       "  collectiveActionLevel  race  \n",
       "0        Call-to-Action   1.0  \n",
       "1             Intention   1.0  \n",
       "2      Problem-Solution   1.0  \n",
       "3      Problem-Solution   1.0  \n",
       "4             Intention   1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "target_counts = {\n",
    "    'Problem-Solution': 188,\n",
    "    'Call-to-Action': 38,\n",
    "    'Intention': 49,\n",
    "    'Execution': 25\n",
    "}\n",
    "\n",
    "matching_rows = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "\n",
    "            filtered = df[(df['race'] == 1) & (df['collectiveAction'] == 0)]\n",
    "            matching_rows.append(filtered)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "all_filtered = pd.concat(matching_rows, ignore_index=True)\n",
    "\n",
    "samples = []\n",
    "for label, count in target_counts.items():\n",
    "    subset = all_filtered[all_filtered['collectiveActionLevel'] == label]\n",
    "    if len(subset) >= count:\n",
    "        samples.append(subset.sample(n=count, random_state=42))\n",
    "    else:\n",
    "        print(f\"Warning: Only {len(subset)} rows available for label '{label}', requested {count}.\")\n",
    "        samples.append(subset)\n",
    "\n",
    "multi_sample = pd.concat(samples).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collectiveActionLevel\n",
       "Problem-Solution    188\n",
       "Intention            49\n",
       "Call-to-Action       38\n",
       "Execution            25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_sample['collectiveActionLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full version\n",
    "multi_sample[['sentenceID', 'sentence', 'race', 'collectiveAction', 'probCollectiveAction', 'collectiveActionLevel']].to_csv(\n",
    "    '../data/annotation/multi_sample.csv', index=False\n",
    ")\n",
    "\n",
    "# Create and save anonymized version\n",
    "anon_df = multi_sample[['sentence']].copy()\n",
    "anon_df['annotation'] = ''  # Placeholder column for annotators\n",
    "\n",
    "anon_df.to_csv('../data/annotation/multi_sample_anon.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
