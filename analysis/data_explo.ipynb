{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data/episodes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/episodeLevelData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category1_counts = df['category1'].value_counts()\n",
    "print(category1_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dates for entire corpus for time series comparison (RQ1)\n",
    "conn = sqlite3.connect('../data/data.db')\n",
    "df = pd.read_sql_query(\"SELECT episodeDateLocalized FROM podcast_episodes\", conn)\n",
    "df.to_csv('../data/all_episodes_dates.csv', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norj_files = os.listdir(\"../data/norjepisodes\")\n",
    "# norj_ids = [os.path.splitext(f)[0] for f in norj_files]\n",
    "# filtered_df = df[~df[\"epID\"].astype(str).isin(norj_ids)]\n",
    "# filtered_df.to_csv(\"../data/episodeLevelData_139.csv\", index=False)\n",
    "# print(f\"Saved filtered file with {len(filtered_df)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_counts = Counter()\n",
    "\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.endswith(\".csv\"):\n",
    "#         file_path = os.path.join(directory, filename)\n",
    "#         try:\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             if 'collectiveAction' in df.columns and 'race' in df.columns:\n",
    "#                 subset = df[df['collectiveAction'] == 0]\n",
    "#                 #race_counts.update(subset['race'].dropna())\n",
    "#                 race_counts.update(subset['race'])  # NaN will be counted as a key\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "# race_summary = pd.DataFrame.from_dict(race_counts, orient='index', columns=['Count']).sort_values(by='Count', ascending=False)\n",
    "# print(race_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of statements of collective action per episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for file in glob.glob(os.path.join(directory, \"*.csv\")):\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        total_rows = len(df)\n",
    "        if total_rows == 0:\n",
    "            continue  \n",
    "\n",
    "        # count rows with both conditions\n",
    "        condition_count = ((df['collectiveAction'] == 0) & (df['race'] == 1)).sum()\n",
    "        proportion = condition_count / total_rows\n",
    "\n",
    "        results.append({\n",
    "            \"file\": os.path.basename(file),\n",
    "            \"total_rows\": total_rows,\n",
    "            \"condition_count\": condition_count,\n",
    "            \"proportion\": proportion\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "summary_stats = results_df[[\"condition_count\", \"proportion\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of statements of each level of collective action per episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from scipy import stats\n",
    "    def t_ci(data, alpha=0.05):\n",
    "        data = np.asarray(data, dtype=float)\n",
    "        n = len(data)\n",
    "        mean = data.mean()\n",
    "        if n < 2 or np.isclose(data.std(ddof=1), 0):\n",
    "            return (mean, mean)  \n",
    "        sem = data.std(ddof=1) / np.sqrt(n)\n",
    "        tcrit = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "        return (mean - tcrit*sem, mean + tcrit*sem)\n",
    "except Exception:\n",
    "    def t_ci(data, alpha=0.05):\n",
    "        data = np.asarray(data, dtype=float)\n",
    "        n = len(data)\n",
    "        mean = data.mean()\n",
    "        if n < 2 or np.isclose(data.std(ddof=1), 0):\n",
    "            return (mean, mean)\n",
    "        sem = data.std(ddof=1) / np.sqrt(n)\n",
    "        z = 1.96 \n",
    "        return (mean - z*sem, mean + z*sem)\n",
    "\n",
    "pattern = os.path.join(directory, \"*.csv\")\n",
    "\n",
    "required_cols = {\"collectiveAction\", \"race\", \"collectiveActionLevel\"}\n",
    "all_props = []          \n",
    "used_files = []         \n",
    "skipped = []            \n",
    "\n",
    "for path in glob.glob(pattern):\n",
    "    try:\n",
    "        if os.path.getsize(path) == 0:\n",
    "            skipped.append((path, \"empty file (0 bytes)\"))\n",
    "            continue\n",
    "    except OSError as e:\n",
    "        skipped.append((path, f\"stat error: {e}\"))\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path, engine=\"python\", on_bad_lines=\"skip\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        skipped.append((path, \"EmptyDataError: no columns/rows\"))\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        skipped.append((path, f\"read error: {e}\"))\n",
    "        continue\n",
    "\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        missing = required_cols - set(df.columns)\n",
    "        skipped.append((path, f\"missing columns: {sorted(missing)}\"))\n",
    "        continue\n",
    "\n",
    "    sub = df[(df[\"collectiveAction\"] == 0) & (df[\"race\"] == 1)]\n",
    "    if sub.empty:\n",
    "        skipped.append((path, \"no rows after filter (collectiveAction==0 & race==1)\"))\n",
    "        continue\n",
    "\n",
    "    props = sub[\"collectiveActionLevel\"].value_counts(normalize=True, dropna=True)\n",
    "\n",
    "    all_props.append(props)\n",
    "    used_files.append(path)\n",
    "\n",
    "if not all_props:\n",
    "    for p, r in skipped:\n",
    "        print(f\"- {os.path.basename(p)} -> {r}\")\n",
    "else:\n",
    "    prop_df = pd.DataFrame(all_props).fillna(0.0)\n",
    "    prop_df.index = [os.path.basename(p) for p in used_files]\n",
    "\n",
    "    means = prop_df.mean(axis=0)\n",
    "    cis = {cat: t_ci(prop_df[cat].values) for cat in prop_df.columns}\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"mean_proportion\": means,\n",
    "        \"ci_lower\": [cis[c][0] for c in means.index],\n",
    "        \"ci_upper\": [cis[c][1] for c in means.index],\n",
    "        \"n_files\": len(used_files)\n",
    "    }).sort_index()\n",
    "\n",
    "    print(\"Per-category average proportions and 95% confidence intervals:\")\n",
    "    print(out.round(4))\n",
    "    print(\"\\nFiles used:\")\n",
    "    for p in used_files:\n",
    "        print(\" -\", os.path.basename(p))\n",
    "\n",
    "    if skipped:\n",
    "        print(\"\\nFiles skipped (reason):\")\n",
    "        for p, r in skipped:\n",
    "            print(f\" - {os.path.basename(p)} -> {r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category counts for collective action levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = 0\n",
    "total_rows = 0\n",
    "total_ca0_rows = 0\n",
    "total_ca0_rj_rows = 0\n",
    "ca0_percentages = []\n",
    "ca0_counts_per_file = []\n",
    "\n",
    "collective_action_level_counts = {}\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, usecols=[\"collectiveAction\", \"collectiveActionLevel\", \"race\"])\n",
    "            total_files += 1\n",
    "            num_rows = len(df)\n",
    "            num_ca0 = (df[\"collectiveAction\"] == 0).sum()\n",
    "            num_rj = (df[\"race\"] == 1).sum()\n",
    "            num_ca0_rj = ((df[\"collectiveAction\"] == 0) & (df[\"race\"] == 1)).sum()\n",
    "\n",
    "            total_rows += num_rows\n",
    "            total_ca0_rj_rows += num_ca0_rj\n",
    "            total_ca0_rows += num_ca0\n",
    "\n",
    "            if num_rows > 0:\n",
    "                ca0_percentages.append(num_ca0_rj / num_rows)\n",
    "            else:\n",
    "                ca0_percentages.append(0)\n",
    "            ca0_counts_per_file.append(num_ca0_rj)\n",
    "\n",
    "            ca0_subset = df[df[\"collectiveAction\"] == 0]\n",
    "            level_counts = ca0_subset[\"collectiveActionLevel\"].value_counts(dropna=False)\n",
    "            for level, count in level_counts.items():\n",
    "                collective_action_level_counts[level] = collective_action_level_counts.get(level, 0) + count\n",
    "\n",
    "        except ValueError as ve:\n",
    "            print(f\"Skipping {filename}: Missing expected columns. ({ve})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "average_ca0_count = sum(ca0_counts_per_file) / total_files if total_files > 0 else 0\n",
    "average_ca0_percentage = sum(ca0_percentages) / total_files if total_files > 0 else 0\n",
    "\n",
    "print(f\"\\nProcessed {total_files} CSV files.\")\n",
    "print(f\"Total number of rows in all files: {total_rows:.2f}\")\n",
    "print(f\"Total number of rows with collectiveAction: {total_ca0_rows:.2f}\")\n",
    "print(f\"Total number of rows with racial justice: {total_ca0_rj_rows:.2f}\")\n",
    "print(f\"Average number of rows with collectiveAction per file: {average_ca0_count:.2f}\")\n",
    "print(f\"Average percentage of rows with collectiveAction per file: {average_ca0_percentage * 100:.2f}%\")\n",
    "print(\"\\nTotal counts for each collectiveActionLevel:\")\n",
    "for level, count in collective_action_level_counts.items():\n",
    "    print(f\"  {level}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequences of collective action statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory = \"../data/episodes\"\n",
    "filtered_rows = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            filtered = df[(df['collectiveAction'] == 0) & (df['race'] == 1)]\n",
    "            if not filtered.empty:\n",
    "                print(f\"Added: {filename}\")\n",
    "                filtered_rows.append(filtered)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "if filtered_rows:\n",
    "    result_df = pd.concat(filtered_rows, ignore_index=True)\n",
    "    result_df.to_csv(\"../data/all_racial_justice_sentences.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
